{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torrevieja Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Station\n",
    "\n",
    "Data about temperature (degree), humidity (%) and pressure (hPa) from weather station.\n",
    "\n",
    "### Input format\n",
    "\n",
    "JSON file has the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"series\": {\n",
    "        \"temperatura\": {\n",
    "            \"sensor-id\": [\n",
    "                [ \"unix-timestamp1\", \"value1\" ],\n",
    "                [ \"unix-timestamp2\", \"value2\" ]\n",
    "            ],\n",
    "        },\n",
    "        \"humedad\": {\n",
    "            \"sensor-name\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        },\n",
    "        \"presion\": {\n",
    "            \"sensor-name\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Output format\n",
    "\n",
    "The output will be a CSV file with the following columns:\n",
    "\n",
    "- `timestamp`\n",
    "- `temperature`\n",
    "- `humidity`\n",
    "- `pressure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"json_data/weather-station\"\n",
    "sensor_id = \"5rTM-4sB-iVpGSRJcSJV_La Mata - Parque Natural_38.02519_-0.65845_0\"\n",
    "file_name = sensor_id.replace(\" \", \"_\") + \"_2024\"\n",
    "file_path = os.path.join(folder_path, file_name + \".json\")\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperature = pd.DataFrame(data['series']['temperatura'][sensor_id], columns=['timestamp', 'temperature'])\n",
    "df_humidity = pd.DataFrame(data['series']['humedad'][sensor_id], columns=['timestamp', 'humidity'])\n",
    "df_pressure = pd.DataFrame(data['series']['presion'][sensor_id], columns=['timestamp', 'pressure'])\n",
    "\n",
    "df_temperature.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_humidity.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_pressure.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "\n",
    "df_weather = pd.merge(df_temperature, df_humidity, how='inner', on='timestamp')\n",
    "df_weather = pd.merge(df_weather, df_pressure, how='inner', on='timestamp')\n",
    "\n",
    "df_weather.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_temperature, df_humidity, df_pressure\n",
    "df_weather.to_csv(file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonometer\n",
    "\n",
    "Data about noise measured by a sonometer in decibels.\n",
    "\n",
    "Data interval: 5 minutes.\n",
    "\n",
    "### Input format\n",
    "\n",
    "JSON file has the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"series\": {\n",
    "        \"noise\": {\n",
    "            \"sensor-id\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        },\n",
    "        \"humidity\": {\n",
    "            \"sensor-name\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        },\n",
    "        \"temperature\": {\n",
    "            \"sensor-name\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Output format\n",
    "\n",
    "The output will be a CSV file with the following columns:\n",
    "\n",
    "- `timestamp`\n",
    "- `noise`\n",
    "\n",
    "`humidity` and `temperature` will be ignored, because are already present in the weather station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"json_data/sonometer\"\n",
    "file_name = \"sonometros_dataset_l1_2024\"\n",
    "file_path = os.path.join(folder_path, file_name + \".json\")\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = list(data['series']['noise'].keys())[0]\n",
    "\n",
    "df_noise = pd.DataFrame(data['series']['noise'][sensor_id], columns=['timestamp', 'noise'])\n",
    "\n",
    "df_noise.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_noise.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise.to_csv(file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buoy\n",
    "\n",
    "Data about water temperature measured in degrees Celsius at different depths (0.2 and 0.7 meters).\n",
    "\n",
    "Data interval: 10 minutes.\n",
    "\n",
    "### Input format\n",
    "\n",
    "JSON file has the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"series\": {\n",
    "        \"temperature_a\": {\n",
    "            \"sensor-1\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "            \"sensor-2\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "            \"...\"\n",
    "        },\n",
    "        \"temperature_b\": {\n",
    "            \"...\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Here, data about water temperature is extracted from `temperature_a`, with 2 different sensors, based on the depths of 0.2 and 0.7 meters respectively.\n",
    "\n",
    "### Output format\n",
    "\n",
    "The output will be a CSV file with the following columns:\n",
    "\n",
    "- `timestamp`\n",
    "- `temperature_02_meters`\n",
    "- `temperature_07_meters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"json_data\"\n",
    "file_name = \"boya_dataset\"\n",
    "file_path = os.path.join(folder_path, file_name + \".json\")\n",
    "\n",
    "id_sensor_02_meters = \"UVztVI0BaNT-uedBhHl1_Profundidad: -0.2m_38.03635_-0.68998_-2.2\"\n",
    "id_sensor_07_meters = \"UVztVI0BaNT-uedBhHl1_Profundidad: -0.7m_38.03635_-0.68998_-2.7\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_02 = pd.DataFrame(data['series']['temperature_a'][id_sensor_02_meters], columns=['timestamp', 'temperature_02'])\n",
    "df_sensor_07 = pd.DataFrame(data['series']['temperature_a'][id_sensor_07_meters], columns=['timestamp', 'temperature_07'])\n",
    "\n",
    "df_sensor_02.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_sensor_07.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "\n",
    "df_water_temperature = pd.merge(df_sensor_02, df_sensor_07, how='inner', on='timestamp')\n",
    "df_water_temperature.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Some temperature measures are invalid (< -10 degrees), so they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_temperature = df_water_temperature[(df_water_temperature['temperature_02'] >= -10.0) & (df_water_temperature['temperature_07'] >= -10.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sensor_02, df_sensor_07\n",
    "df_water_temperature.to_csv(file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagoon depth\n",
    "\n",
    "Data about the depth of the lagoon measured in cm.\n",
    "\n",
    "Data interval: 1 hour\n",
    "\n",
    "### Input format\n",
    "\n",
    "JSON file has the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"series\": {\n",
    "        \"profundidad\": {\n",
    "            \"sensor-id\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Output format\n",
    "\n",
    "The output will be a CSV file with the following columns:\n",
    "\n",
    "- `timestamp`\n",
    "- `depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"json_data\"\n",
    "file_name = \"profundidadlaguna_dataset\"\n",
    "file_path = os.path.join(folder_path, file_name + \".json\")\n",
    "\n",
    "sensor_id = \"jRCJ548B1ljoqTiFLu0b_mqtt_consumerNivel laguna_38.02050_-0.66930_1\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagoon_depth = pd.DataFrame(data['series']['profundidad'][sensor_id], columns=['timestamp', 'depth'])\n",
    "\n",
    "df_lagoon_depth.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_lagoon_depth.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Measures that differ more that a `threshold` from the previous one will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10\n",
    "\n",
    "df_lagoon_depth['diff'] = df_lagoon_depth['depth'].diff()\n",
    "df_lagoon_depth['diff'] = df_lagoon_depth['diff'].abs()\n",
    "df_lagoon_depth = df_lagoon_depth[df_lagoon_depth['diff'] <= threshold]\n",
    "\n",
    "df_lagoon_depth.drop(columns=['diff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagoon_depth.to_csv(file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitors counter\n",
    "\n",
    "Data about the numeber of visitors in the park.\n",
    "\n",
    "Data interval:\n",
    "- 1.5 minutes for sensors 1\n",
    "- 5 minutes for sensors 2\n",
    "\n",
    "### Input format\n",
    "\n",
    "JSON file has the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"series\": {\n",
    "        \"sensor-id\": {\n",
    "            \"count-in\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ],\n",
    "            \"count-out\": [\n",
    "                [ \"unix-timestamp\", \"value\" ]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Output format\n",
    "\n",
    "The output will be a CSV file with the following columns:\n",
    "\n",
    "- `timestamp`\n",
    "- `count_in_sensor1`\n",
    "- `count_out_sensor1`\n",
    "- `count_in_sensor2`\n",
    "- `count_out_sensor2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"json_data\"\n",
    "file_name_sensor1 = \"api_response1_entrance_outdoor\"\n",
    "file_name_sensor2 = \"api_response2_cementery_outdoor\"\n",
    "file_path_sensor1 = os.path.join(folder_path, file_name_sensor1 + \".json\")\n",
    "file_path_sensor2 = os.path.join(folder_path, file_name_sensor2 + \".json\")\n",
    "\n",
    "with open(file_path_sensor1) as f:\n",
    "    data_sensor1 = json.load(f)\n",
    "\n",
    "with open(file_path_sensor2) as f:\n",
    "    data_sensor2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitors_in_sensor1 = pd.DataFrame(data_sensor1['series']['hup4zYsBoTGoLusGWiIj_centro_38.02516_-0.65839_8']['count_in'], columns=['timestamp', 'count_in'])\n",
    "df_visitors_out_sensor1 = pd.DataFrame(data_sensor1['series']['hup4zYsBoTGoLusGWiIj_centro_38.02516_-0.65839_8']['count_out'], columns=['timestamp', 'count_out'])\n",
    "\n",
    "df_visitors_in_sensor1.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_visitors_out_sensor1.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "\n",
    "df_visitors_sensor1 = pd.merge(df_visitors_in_sensor1, df_visitors_out_sensor1, how='inner', on='timestamp')\n",
    "df_visitors_sensor1.set_index('timestamp', inplace=True)\n",
    "\n",
    "# df_visitors_sensor1[\"date\"] = pd.to_datetime(df_visitors_sensor1.index, unit='ms')\n",
    "# df_visitors_sensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitors_in_sensor2 = pd.DataFrame(data_sensor2['series']['5Ql2zYsBW9nuZhXkjyc1_centro_38.02516_-0.65839_8']['count_in'], columns=['timestamp', 'count_in'])\n",
    "df_visitors_out_sensor2 = pd.DataFrame(data_sensor2['series']['5Ql2zYsBW9nuZhXkjyc1_centro_38.02516_-0.65839_8']['count_out'], columns=['timestamp', 'count_out'])\n",
    "\n",
    "df_visitors_in_sensor2.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "df_visitors_out_sensor2.drop_duplicates(subset='timestamp', keep='first', inplace=True)\n",
    "\n",
    "df_visitors_sensor2 = pd.merge(df_visitors_in_sensor2, df_visitors_out_sensor2, how='inner', on='timestamp')\n",
    "df_visitors_sensor2.set_index('timestamp', inplace=True)\n",
    "\n",
    "# df_visitors_sensor2[\"date\"] = pd.to_datetime(df_visitors_sensor2.index, unit='ms')\n",
    "# df_visitors_sensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations on merging sensors data\n",
    "\n",
    "Both sensors have different data timestamp, so a pure merge join is not possible. The idea is to merge the timestamp with the nearest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitors_sensor1.sort_index(inplace=True)\n",
    "df_visitors_sensor2.sort_index(inplace=True)\n",
    "\n",
    "df_visitors = pd.merge_asof(df_visitors_sensor1, df_visitors_sensor2, on='timestamp', direction='nearest', suffixes=('_sensor1', '_sensor2'))\n",
    "df_visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitors.to_csv(\"visitors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torrevieja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
